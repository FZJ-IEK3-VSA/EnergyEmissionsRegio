{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once the best model is chosen based on the experiments on the computational cluster, the model is used to impute the missing data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from energyemissionsregio.config import DATA_PATH\n",
    "from energyemissionsregio.utils import get_confidence_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_to_impute = \"es_utilized_agricultural_area\"\n",
    "best_corr_threshold = 0.1\n",
    "r2 = 0.83\n",
    "\n",
    "imputed_value_confidence_level = get_confidence_level(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "        os.path.join(\n",
    "            cwd, \"..\", \"..\", \"data\", \"missing_value_imputation\", \"predictor_vars\", f\"{var_to_impute}_{best_corr_threshold}corr.json\"\n",
    "        )\n",
    "    ) as f:\n",
    "        predictor_vars = tuple(json.load(f))\n",
    "\n",
    "X_vars_df = None\n",
    "\n",
    "for var_name in predictor_vars:\n",
    "    _df = pd.read_csv(\n",
    "        os.path.join(DATA_PATH, f\"{var_name}.csv\")\n",
    "    )\n",
    "    _df = _df[_df[\"region_code\"].str.startswith((\"DE\", \"ES\"))][[\"region_code\", \"value\"]].copy()\n",
    "\n",
    "    _df = _df.fillna(0) # filling NAs for point vars. \n",
    "\n",
    "    _df.rename(columns={\"value\": var_name}, inplace=True)\n",
    "\n",
    "    if X_vars_df is not None:\n",
    "        X_vars_df = pd.merge(X_vars_df, _df, on=\"region_code\", how=\"outer\")\n",
    "    else:\n",
    "        X_vars_df = _df\n",
    "\n",
    "y_var_df = pd.read_csv(\n",
    "        os.path.join(DATA_PATH, f\"{var_to_impute}.csv\")\n",
    "    )\n",
    "\n",
    "y_var_df = y_var_df[y_var_df[\"region_code\"].str.startswith((\"DE\", \"ES\"))][[\"region_code\", \"value\"]].copy()\n",
    "y_var_df.rename(columns={\"value\": var_to_impute}, inplace=True)\n",
    "\n",
    "final_df = pd.merge(X_vars_df, y_var_df, on=\"region_code\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = final_df.copy()\n",
    "input_df = input_df[input_df[var_to_impute].isna()].drop(columns=[var_to_impute])\n",
    "\n",
    "input_df_no_reg_code = input_df.drop(columns=[\"region_code\"])\n",
    "\n",
    "# Construct the file path\n",
    "file_path = os.path.join(cwd, \"..\", \"..\", \n",
    "                         \"data\", \n",
    "                         \"missing_value_imputation\", \n",
    "                         \"models\", \n",
    "                         f\"{var_to_impute}_xgb_{best_corr_threshold}corr.pkl\")\n",
    "\n",
    "# Load the model from the pickle file\n",
    "with open(file_path, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "y_pred = model.predict(input_df_no_reg_code)\n",
    "y_pred = y_pred.round(2)\n",
    "\n",
    "input_df['imputed_values'] = y_pred\n",
    "\n",
    "assert input_df[input_df[\"region_code\"].str.startswith(\"DE\")][\"imputed_values\"].min() >= 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imputed_df = final_df[[\"region_code\", var_to_impute]].copy()\n",
    "imputed_df.rename(columns={var_to_impute: \"value\"}, inplace=True) \n",
    "\n",
    "imputed_df[\"value_confidence_level\"] = 5 # VERY HIGH \n",
    "\n",
    "for idx, row in final_df.iterrows():\n",
    "    region_code = row[\"region_code\"]\n",
    "\n",
    "    if math.isnan(row[var_to_impute]):\n",
    "\n",
    "        imputed_df.loc[idx, \"value\"] = input_df[input_df[\"region_code\"] == region_code][[\"imputed_values\"]].values.item()\n",
    "        imputed_df.loc[idx, \"value_confidence_level\"] = imputed_value_confidence_level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df.to_csv(os.path.join(\n",
    "            cwd, \"..\", \"..\", \"data\", \"imputed_data\", f\"{var_to_impute}.csv\"\n",
    "        ), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
