{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from energyemissionsregio.config import DATA_PATH\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### potential predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lau_vars = [\n",
    "    \"population\", \n",
    "             \"area\", \n",
    "             'continuous_urban_fabric_cover',\n",
    "       'discontinuous_urban_fabric_cover',\n",
    "       'industrial_or_commercial_units_cover',\n",
    "       'port_areas_cover',\n",
    "       'airports_cover', 'mineral_extraction_sites_cover',\n",
    "       'dump_sites_cover', 'construction_sites_cover',\n",
    "       'green_urban_areas_cover', 'sport_and_leisure_facilities_cover',\n",
    "       'non_irrigated_arable_land_cover',\n",
    "       'permanently_irrigated_land_cover', 'rice_fields_cover',\n",
    "       'vineyards_cover', 'fruit_trees_and_berry_plantations_cover',\n",
    "       'olive_groves_cover', 'pastures_cover', 'permanent_crops_cover',\n",
    "       'complex_cultivation_patterns_cover',\n",
    "       'agriculture_with_natural_vegetation_cover',\n",
    "       'agro_forestry_areas_cover', 'broad_leaved_forest_cover',\n",
    "       'coniferous_forest_cover', 'mixed_forest_cover',\n",
    "       'natural_grasslands_cover', 'moors_and_heathland_cover',\n",
    "       'sclerophyllous_vegetation_cover',\n",
    "       'transitional_woodland_shrub_cover',\n",
    "       'beaches_dunes_and_sand_cover', \n",
    "       'bare_rocks_cover',\n",
    "       'sparsely_vegetated_areas_cover', 'burnt_areas_cover',\n",
    "       'glaciers_and_perpetual_snow_cover', 'inland_marshes_cover',\n",
    "       'peat_bogs_cover', \n",
    "       'salt_marshes_cover', \n",
    "       'salines_cover',\n",
    "       'intertidal_flats_cover', 'water_courses_cover',\n",
    "       'water_bodies_cover', 'coastal_lagoons_cover', 'estuaries_cover',\n",
    "       'sea_and_ocean_cover',\n",
    "       \"number_of_iron_and_steel_industries\",\n",
    "      \"number_of_cement_industries\",\n",
    "      \"number_of_refineries\",\n",
    "      \"number_of_paper_and_printing_industries\",\n",
    "      \"number_of_chemical_industries\",\n",
    "      \"number_of_glass_industries\",\n",
    "      \"number_of_non_ferrous_metals_industries\",\n",
    "      \"number_of_non_metallic_minerals_industries\",\n",
    "       \"railway_network\",\n",
    "       \"road_network\",\n",
    "       \"number_of_buildings\",\n",
    "       'average_air_pollution_due_to_pm2.5',\n",
    "       'average_air_pollution_due_to_no2',\n",
    "       'average_air_pollution_due_to_o3',\n",
    "       'average_air_pollution_due_to_pm10',\n",
    "       'number_of_buffaloes', 'number_of_cattle', 'number_of_pigs',\n",
    "       'number_of_sheeps', 'number_of_chickens', 'number_of_goats',\n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUTS3 data with no missing values\n",
    "nuts3_vars = [\"employment_in_agriculture_forestry_and_fishing\", \n",
    "                  \"employment_in_manufacturing\",\n",
    "                  \"employment_in_construction\",\n",
    "                  \"gross_domestic_product\",\n",
    "                  \"road_transport_of_freight\",\n",
    "                  \"soil_sealing\",\n",
    "                  \"cproj_annual_mean_temperature_heating_degree_days\",\n",
    "                  \"cproj_annual_mean_temperature_cooling_degree_days\",\n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = pd.read_excel(\n",
    "    os.path.join(DATA_PATH, \"..\", \"..\", \"01_raw\", \"variables_with_details_and_tags.xlsx\"),\n",
    "    sheet_name=\"collected_variables_EU\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars_lau = lau_vars.copy()\n",
    "x_vars_nuts3 = nuts3_vars.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vars_df = None\n",
    "\n",
    "for var_name in x_vars_lau:\n",
    "    \n",
    "    _df = pd.read_csv(\n",
    "        os.path.join(DATA_PATH, f\"{var_name}.csv\")\n",
    "    )\n",
    "    _df = _df[_df[\"region_code\"].str.startswith(\"DE\")][[\"region_code\", \"value\"]].copy()\n",
    "\n",
    "    _df = _df.fillna(0) # filling NAs for point vars. Non-point vars have no NAs in Germany\n",
    "\n",
    "    #convert LAU to NUTS3 regions\n",
    "    _df[\"region_code\"] = _df[\"region_code\"].str.split(\"_\").str[0]\n",
    "\n",
    "    # aggregate per NUTS3 region \n",
    "    agg_method = var_df[var_df[\"var_name\"] == var_name][\n",
    "            \"var_aggregation_method\"\n",
    "        ].values[0]\n",
    "\n",
    "    if agg_method == \"SUM\":\n",
    "        _df = _df.groupby(\"region_code\").sum().reset_index()\n",
    "    elif agg_method == \"AVG\":\n",
    "        _df = _df.groupby(\"region_code\").mean().reset_index()\n",
    "    elif agg_method == \"MAX\":\n",
    "        _df = _df.groupby(\"region_code\").max().reset_index()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown var aggregation method\")\n",
    "\n",
    "    _df.rename(columns={\"value\": var_name}, inplace=True)\n",
    "\n",
    "    if X_vars_df is not None:\n",
    "        X_vars_df = pd.merge(X_vars_df, _df, on=\"region_code\", how=\"outer\")\n",
    "    else:\n",
    "        X_vars_df = _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_name in x_vars_nuts3:\n",
    "    if var_name.startswith(\"cproj_\"):\n",
    "        _df = pd.read_csv(os.path.join(DATA_PATH, \"..\", \"climate_projections\", \"DE\", var_name, \"2020.csv\"))\n",
    "        _df = _df[_df[\"climate_experiment\"] == \"RCP4.5\"].copy()\n",
    "\n",
    "        _df.drop(columns=\"climate_experiment\", inplace=True)\n",
    "        \n",
    "    else:\n",
    "        _df = pd.read_csv(\n",
    "            os.path.join(DATA_PATH, f\"{var_name}.csv\")\n",
    "        )\n",
    "        _df = _df[_df[\"region_code\"].str.startswith(\"DE\")][[\"region_code\", \"value\"]].copy()\n",
    "    \n",
    "    _df.rename(columns={\"value\": var_name}, inplace=True)\n",
    "\n",
    "    if X_vars_df is not None:\n",
    "        X_vars_df = pd.merge(X_vars_df, _df, on=\"region_code\", how=\"outer\")\n",
    "    else:\n",
    "        X_vars_df = _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vars_df.isna().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop 0  variance columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_cols = X_vars_df.select_dtypes(include=['number'])\n",
    "variance = numerical_cols.var()\n",
    "\n",
    "# Identify columns with zero variance\n",
    "zero_variance_cols = variance[variance == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_variance_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vars_df.drop(columns=zero_variance_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### between paris of variables that are highly correlated, drop 1 variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_vars_corr = X_vars_df.copy()\n",
    "relevant_vars_corr.drop(columns=\"region_code\", inplace=True)\n",
    "\n",
    "corr_df = relevant_vars_corr.corr()\n",
    "\n",
    "for idx, row in corr_df.iterrows():\n",
    "    temp_dict = dict(row)\n",
    "    for key, value in temp_dict.items():\n",
    "        if (idx != key) & (value>=0.9):\n",
    "            print(f\"{idx} and {key} are highly correlated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: some variable pairs did not show high correlation at LAU level, but when aggregation to NUTS3, they show high correlation. This shows that the strong relationships that exists at NUTS3 cannot be used at LAU to disaggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_drop = [\"population\", \"bare_rocks_cover\", \"salt_marshes_cover\", \"average_air_pollution_due_to_pm10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vars_df.drop(columns=vars_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_impute = [\"de_employment_in_food_and_beverage_manufacturing\",\n",
    "                  \"de_employment_in_mechanical_and_automotive_engineering\",\n",
    "                  \"de_employment_in_mechatronics_energy_and_electrical\",\n",
    "                  \"de_employment_in_agriculture\",\n",
    "                  \"de_employment_in_wood_processing\",\n",
    "                  \"de_employment_in_textile_and_leather_manufacturing\",\n",
    "                  \"de_number_of_passenger_cars_emission_group_euro_1\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_2\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_3\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_4\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_5\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_6r\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_6dt\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_6d\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_other\",\n",
    "\"de_residential_building_living_area\",\n",
    "\"de_non_residential_building_living_area\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_to_impute in vars_to_impute:\n",
    "    y_var_df = pd.read_csv(\n",
    "        os.path.join(DATA_PATH, f\"{var_to_impute}.csv\")\n",
    "    )\n",
    "\n",
    "    ## only Germany data is taken because the list of vars in vars_to_impute are avaiable only for Germany. Missing value imputation is done for the regions in Germany with missing data \n",
    "    # and all the regions in Spain\n",
    "    y_var_df = y_var_df[y_var_df[\"region_code\"].str.startswith(\"DE\")][[\"region_code\", \"value\"]].copy()\n",
    "    y_var_df.rename(columns={\"value\": var_to_impute}, inplace=True)\n",
    "\n",
    "    final_df_with_reg_code = pd.merge(X_vars_df, y_var_df, on=\"region_code\", how=\"outer\")\n",
    "\n",
    "    final_df = final_df_with_reg_code.copy()\n",
    "    final_df.drop(columns=\"region_code\", inplace=True)\n",
    "\n",
    "    for corr_threshold in [0.1, 0.5]:\n",
    "        final_df = final_df.reindex(sorted(final_df.columns), axis=1)\n",
    "\n",
    "        correlations = final_df.corr()[[var_to_impute]].drop(var_to_impute)\n",
    "        correlations = correlations[(correlations[var_to_impute] <=-corr_threshold) | (correlations[var_to_impute] >=corr_threshold)]\n",
    "\n",
    "        correlations = correlations.transpose()\n",
    "\n",
    "        chosen_vars = list(correlations.columns)\n",
    "        chosen_vars.extend([var_to_impute])\n",
    "\n",
    "        save_df = final_df[chosen_vars].copy()\n",
    "\n",
    "        save_df.to_csv(os.path.join(\"..\", \"..\", \"data\", \n",
    "                                    \"missing_value_imputation\", \n",
    "                                    f\"{var_to_impute}_{corr_threshold}corr.csv\"), index=False)\n",
    "        \n",
    "        predictor_vars = list(save_df.columns)\n",
    "        predictor_vars.remove(var_to_impute)\n",
    "\n",
    "        with open(\n",
    "            os.path.join(\"..\", \"..\", \"data\", \"missing_value_imputation\", \n",
    "                         \"predictor_vars\", \n",
    "                         f\"{var_to_impute}_{corr_threshold}corr.json\"), \"w\"\n",
    "        ) as fp:\n",
    "            json.dump(list(predictor_vars), fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_impute = [\"de_employment_in_food_and_beverage_manufacturing\",\n",
    "                  \"de_employment_in_mechanical_and_automotive_engineering\",\n",
    "                  \"de_employment_in_mechatronics_energy_and_electrical\",\n",
    "                  \"de_employment_in_agriculture\",\n",
    "                  \"de_employment_in_wood_processing\",\n",
    "                  \"de_employment_in_textile_and_leather_manufacturing\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = X_vars_df.copy()\n",
    "for var_to_impute in vars_to_impute:\n",
    "    y_var_df = pd.read_csv(\n",
    "        os.path.join(DATA_PATH, f\"{var_to_impute}.csv\")\n",
    "    )\n",
    "\n",
    "    y_var_df = y_var_df[y_var_df[\"region_code\"].str.startswith(\"DE\")][[\"region_code\", \"value\"]].copy()\n",
    "    y_var_df.rename(columns={\"value\": var_to_impute}, inplace=True)\n",
    "\n",
    "    corr_df = pd.merge(corr_df, y_var_df, on=\"region_code\", how=\"outer\")\n",
    "\n",
    "corr_df.drop(columns=\"region_code\", inplace=True)\n",
    "\n",
    "correlations = corr_df.corr()[vars_to_impute].drop(vars_to_impute)\n",
    "correlations = correlations.round(2)\n",
    "correlations = correlations.transpose()\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(15, 3))  # Adjust the figure size as needed\n",
    "sns.heatmap(correlations.abs(), annot=True, cmap=\"Blues\", cbar=True, annot_kws={\"rotation\": 90}, vmin=0, vmax=1 )\n",
    "plt.savefig(os.path.join(\"..\", \"..\", \"figures\", \"missing_value_imputation\", \n",
    "                            f\"employment_corr.png\"), \n",
    "                            bbox_inches='tight')  # Save the figure as a PNG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_impute = [\n",
    "                  \"de_number_of_passenger_cars_emission_group_euro_1\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_2\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_3\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_4\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_5\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_6r\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_6dt\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_6d\",\n",
    "\"de_number_of_passenger_cars_emission_group_euro_other\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = X_vars_df.copy()\n",
    "for var_to_impute in vars_to_impute:\n",
    "    y_var_df = pd.read_csv(\n",
    "        os.path.join(DATA_PATH, f\"{var_to_impute}.csv\")\n",
    "    )\n",
    "\n",
    "    y_var_df = y_var_df[y_var_df[\"region_code\"].str.startswith(\"DE\")][[\"region_code\", \"value\"]].copy()\n",
    "    y_var_df.rename(columns={\"value\": var_to_impute}, inplace=True)\n",
    "\n",
    "    corr_df = pd.merge(corr_df, y_var_df, on=\"region_code\", how=\"outer\")\n",
    "\n",
    "corr_df.drop(columns=\"region_code\", inplace=True)\n",
    "\n",
    "correlations = corr_df.corr()[vars_to_impute].drop(vars_to_impute)\n",
    "correlations = correlations.round(2)\n",
    "correlations = correlations.transpose()\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(15, 5))  # Adjust the figure size as needed\n",
    "sns.heatmap(correlations.abs(), annot=True, cmap=\"Blues\", cbar=True, annot_kws={\"rotation\": 90}, vmin=0, vmax=1 )\n",
    "plt.savefig(os.path.join(\"..\", \"..\", \"figures\", \"missing_value_imputation\", \n",
    "                            f\"passenger_cars_emissions.png\"), \n",
    "                            bbox_inches='tight')  # Save the figure as a PNG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_impute = [\n",
    "\"de_residential_building_living_area\",\n",
    "\"de_non_residential_building_living_area\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = X_vars_df.copy()\n",
    "for var_to_impute in vars_to_impute:\n",
    "    y_var_df = pd.read_csv(\n",
    "        os.path.join(DATA_PATH, f\"{var_to_impute}.csv\")\n",
    "    )\n",
    "\n",
    "    y_var_df = y_var_df[y_var_df[\"region_code\"].str.startswith(\"DE\")][[\"region_code\", \"value\"]].copy()\n",
    "    y_var_df.rename(columns={\"value\": var_to_impute}, inplace=True)\n",
    "\n",
    "    corr_df = pd.merge(corr_df, y_var_df, on=\"region_code\", how=\"outer\")\n",
    "\n",
    "corr_df.drop(columns=\"region_code\", inplace=True)\n",
    "\n",
    "correlations = corr_df.corr()[vars_to_impute].drop(vars_to_impute)\n",
    "correlations = correlations.round(2)\n",
    "correlations = correlations.transpose()\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(15, 1))  # Adjust the figure size as needed\n",
    "sns.heatmap(correlations.abs(), annot=True, cmap=\"Blues\", cbar=True, annot_kws={\"rotation\": 90}, vmin=0, vmax=1 )\n",
    "plt.savefig(os.path.join(\"..\", \"..\", \"figures\", \"missing_value_imputation\", \n",
    "                            f\"building_living_area.png\"), \n",
    "                            bbox_inches='tight')  # Save the figure as a PNG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
