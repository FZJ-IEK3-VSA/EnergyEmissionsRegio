{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from energyemissionsregio.config import DATA_PATH\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### potential predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = pd.read_excel(\n",
    "    os.path.join(DATA_PATH, \"..\", \"..\", \"01_raw\", \"variables_with_details_and_tags.xlsx\"),\n",
    "    sheet_name=\"collected_variables_EU\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\"population\", \n",
    "             \"area\", \n",
    "             'continuous_urban_fabric_cover',\n",
    "       'discontinuous_urban_fabric_cover',\n",
    "       'industrial_or_commercial_units_cover',\n",
    "       'port_areas_cover',\n",
    "       'airports_cover', 'mineral_extraction_sites_cover',\n",
    "       'dump_sites_cover', 'construction_sites_cover',\n",
    "       'green_urban_areas_cover', 'sport_and_leisure_facilities_cover',\n",
    "       'non_irrigated_arable_land_cover',\n",
    "       'permanently_irrigated_land_cover', 'rice_fields_cover',\n",
    "       'vineyards_cover', 'fruit_trees_and_berry_plantations_cover',\n",
    "       'olive_groves_cover', 'pastures_cover', 'permanent_crops_cover',\n",
    "       'complex_cultivation_patterns_cover',\n",
    "       'agriculture_with_natural_vegetation_cover',\n",
    "       'agro_forestry_areas_cover', 'broad_leaved_forest_cover',\n",
    "       'coniferous_forest_cover', 'mixed_forest_cover',\n",
    "       'natural_grasslands_cover', 'moors_and_heathland_cover',\n",
    "       'sclerophyllous_vegetation_cover',\n",
    "       'transitional_woodland_shrub_cover',\n",
    "       'beaches_dunes_and_sand_cover', 'bare_rocks_cover',\n",
    "       'sparsely_vegetated_areas_cover', 'burnt_areas_cover',\n",
    "       'glaciers_and_perpetual_snow_cover', 'inland_marshes_cover',\n",
    "       'peat_bogs_cover', 'salt_marshes_cover', 'salines_cover',\n",
    "       'intertidal_flats_cover', 'water_courses_cover',\n",
    "       'water_bodies_cover', 'coastal_lagoons_cover', 'estuaries_cover',\n",
    "       'sea_and_ocean_cover',\n",
    "       \"number_of_iron_and_steel_industries\",\n",
    "      \"number_of_cement_industries\",\n",
    "      \"number_of_refineries\",\n",
    "      \"number_of_paper_and_printing_industries\",\n",
    "      \"number_of_chemical_industries\",\n",
    "      \"number_of_glass_industries\",\n",
    "      \"number_of_non_ferrous_metals_industries\",\n",
    "      \"number_of_non_metallic_minerals_industries\",\n",
    "       \"railway_network\",\n",
    "       \"road_network\",\n",
    "       \"number_of_buildings\",\n",
    "       'average_air_pollution_due_to_pm2.5',\n",
    "       'average_air_pollution_due_to_no2',\n",
    "       'average_air_pollution_due_to_o3',\n",
    "       'average_air_pollution_due_to_pm10',\n",
    "       'number_of_buffaloes', 'number_of_cattle', 'number_of_pigs',\n",
    "       'number_of_sheeps', 'number_of_chickens', 'number_of_goats',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get predictor data for es_utilized_agricultural_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_to_impute = \"es_utilized_agricultural_area\"\n",
    "\n",
    "x_vars = vars.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vars_df = None\n",
    "\n",
    "for var_name in x_vars:\n",
    "    _df = pd.read_csv(\n",
    "        os.path.join(DATA_PATH, f\"{var_name}.csv\")\n",
    "    )\n",
    "    ## only Spain data is taken because es_utilized_agricultural_area is avaiable only for Spain. \n",
    "    # Missing value imputation is done for the regions in Spain with missing data \n",
    "    # and all the regions in Germany\n",
    "    _df = _df[_df[\"region_code\"].str.startswith(\"ES\")][[\"region_code\", \"value\"]].copy() \n",
    "    _df.rename(columns={\"value\": var_name}, inplace=True)\n",
    "\n",
    "    if X_vars_df is not None:\n",
    "        X_vars_df = pd.merge(X_vars_df, _df, on=\"region_code\", how=\"outer\")\n",
    "    else:\n",
    "        X_vars_df = _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sources, including Corine Land Cover, OpenStreetMap, and SEEnergies, provide spatial data either as raster files or at \n",
    "# specific X-Y coordinates. This spatial information is overlain with LAU regions and aggregated at the LAU level to create \n",
    "# regional datasets. If no data points overlap with a given LAU region, the value is set to zero\n",
    "X_vars_df = X_vars_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_vars_corr = X_vars_df.copy()\n",
    "relevant_vars_corr.drop(columns=\"region_code\", inplace=True)\n",
    "\n",
    "corr_df = relevant_vars_corr.corr()\n",
    "\n",
    "for idx, row in corr_df.iterrows():\n",
    "    temp_dict = dict(row)\n",
    "    for key, value in temp_dict.items():\n",
    "        if (idx != key) & (value>=0.9):\n",
    "            print(f\"{idx} and {key} are highly correlated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var_df = pd.read_csv(\n",
    "        os.path.join(DATA_PATH, f\"{var_to_impute}.csv\")\n",
    "    )\n",
    "\n",
    "y_var_df = y_var_df[y_var_df[\"region_code\"].str.startswith(\"ES\")][[\"region_code\", \"value\"]].copy()\n",
    "y_var_df.rename(columns={\"value\": var_to_impute}, inplace=True)\n",
    "\n",
    "final_df_with_reg_code = pd.merge(X_vars_df, y_var_df, on=\"region_code\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df_with_reg_code.copy()\n",
    "final_df.drop(columns=\"region_code\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.reindex(sorted(final_df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlations between utilized_agricultural_area and predictor vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = final_df.corr()[[var_to_impute]].drop(var_to_impute)\n",
    "\n",
    "correlations = correlations.transpose()\n",
    "correlations = correlations.round(2)\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(18, 1))  # Adjust the figure size as needed\n",
    "sns.heatmap(correlations.abs(), annot=True, cmap=\"Blues\", cbar=True, annot_kws={\"rotation\": 90}, vmin=0, vmax=1)\n",
    "plt.yticks([])\n",
    "plt.savefig(os.path.join(\"..\", \"..\", \"figures\", \"missing_value_imputation\", f\"{var_to_impute}.png\"), bbox_inches='tight')  # Save the figure as a PNG file\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save two sets of data for missing value imputation - predictors with correlation 0.1 and above with utilized_agricultural_area and 0.5 and above. \n",
    "### missing value imputation is performed on a computational server at FZJ. The imputation script: energyemissiosnregio/CAESAR_scripts/xg_boost.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = final_df.corr()[[var_to_impute]].drop(var_to_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corr_threshold in [0.1, 0.5]:\n",
    "    \n",
    "    final_df = final_df.reindex(sorted(final_df.columns), axis=1)\n",
    "\n",
    "    correlations = final_df.corr()[[var_to_impute]].drop(var_to_impute)\n",
    "    correlations = correlations[(correlations[var_to_impute] <=-corr_threshold) | (correlations[var_to_impute] >=corr_threshold)]\n",
    "    \n",
    "    correlations = correlations.transpose()\n",
    "\n",
    "    chosen_vars = list(correlations.columns)\n",
    "    chosen_vars.extend([var_to_impute])\n",
    "\n",
    "    save_df = final_df[chosen_vars].copy()\n",
    "\n",
    "    save_df.to_csv(os.path.join(\"..\", \"..\", \"data\", \n",
    "                                \"missing_value_imputation\", \n",
    "                                f\"{var_to_impute}_{corr_threshold}corr.csv\"), index=False)\n",
    "\n",
    "    predictor_vars = list(save_df.columns)\n",
    "    predictor_vars.remove(var_to_impute)\n",
    "\n",
    "    with open(\n",
    "        os.path.join(\"..\", \"..\", \"data\", \"missing_value_imputation\", \n",
    "                     \"predictor_vars\", \n",
    "                     f\"{var_to_impute}_{corr_threshold}corr.json\"), \"w\"\n",
    "    ) as fp:\n",
    "        json.dump(list(predictor_vars), fp)\n",
    "\n",
    "    print(f\"saved data for {corr_threshold} correlation threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
